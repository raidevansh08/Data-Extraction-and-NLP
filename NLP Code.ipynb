{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8ef9db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\devan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\devan\\anaconda3\\lib\\site-packages (3.5.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy) (1.10.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy) (8.1.9)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy) (1.20.3)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\devan\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy) (58.0.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\devan\\appdata\\roaming\\python\\python39\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.5.0) (3.5.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\devan\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (21.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.20.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.26.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (58.0.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.11.3)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.62.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\devan\\appdata\\roaming\\python\\python39\\site-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textstat in c:\\users\\devan\\anaconda3\\lib\\site-packages (0.7.3)\n",
      "Requirement already satisfied: pyphen in c:\\users\\devan\\anaconda3\\lib\\site-packages (from textstat) (0.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29b7661f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL\n",
       "0    37.0  https://insights.blackcoffer.com/ai-in-healthc...\n",
       "1    38.0  https://insights.blackcoffer.com/what-if-the-c...\n",
       "2    39.0  https://insights.blackcoffer.com/what-jobs-wil...\n",
       "3    40.0  https://insights.blackcoffer.com/will-machine-...\n",
       "4    41.0  https://insights.blackcoffer.com/will-ai-repla..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"Input.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2654326",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    url_id = row['URL_ID']\n",
    "    url = row['URL']\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    article = soup.find('article')\n",
    "    if article is None:\n",
    "        print(f\"No article found on webpage: {url}\")\n",
    "        continue\n",
    "    title = article.find('h1').get_text().strip()\n",
    "    text = '\\n'.join([p.get_text().strip() for p in article.find_all('p')])\n",
    "    with open(f\"{url_id}.txt\", 'w', encoding='utf-8') as file:\n",
    "        file.write(title + '\\n\\n' + text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24231214",
   "metadata": {},
   "source": [
    "### Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3b75da",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_dir = \"stopwords\"\n",
    "stopwords_set = set()\n",
    "\n",
    "# Load stopwords from all files in stopwords_dir\n",
    "for filename in os.listdir(stopwords_dir):\n",
    "    with open(os.path.join(stopwords_dir, filename), 'r', encoding='latin1') as file:\n",
    "        stopwords_set.update(word.strip().lower() for word in file.readlines())\n",
    "\n",
    "# Loop over each article file and remove stopwords\n",
    "for index, row in df.iterrows():\n",
    "    url_id = row['URL_ID']\n",
    "    try:\n",
    "        with open(f\"{url_id}.txt\", 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"WARNING: File {url_id}.txt not found, skipping.\")\n",
    "        continue\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords_set]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    with open(f\"{url_id}_cleaned.txt\", 'w', encoding='utf-8') as file:\n",
    "        file.write(filtered_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff08dc1",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70482ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>Positive_Words</th>\n",
       "      <th>Negative_Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>22</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.0</td>\n",
       "      <td>24</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103.0</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.0</td>\n",
       "      <td>26</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>95.0</td>\n",
       "      <td>29</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>96.0</td>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>97.0</td>\n",
       "      <td>13</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>98.0</td>\n",
       "      <td>33</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>99.0</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    URL_ID  Positive_Words  Negative_Words\n",
       "0    100.0              22              41\n",
       "1    101.0               3               3\n",
       "2    102.0              24              43\n",
       "3    103.0               6              24\n",
       "4    104.0              26              54\n",
       "..     ...             ...             ...\n",
       "106   95.0              29              33\n",
       "107   96.0              16              41\n",
       "108   97.0              13              41\n",
       "109   98.0              33              48\n",
       "110   99.0              21              27\n",
       "\n",
       "[111 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the directory containing the cleaned article text files\n",
    "cleaned_dir = './Cleaned_Article_Texts/'\n",
    "\n",
    "# Path to the directory containing the master dictionary text files\n",
    "dictionary_dir = './MasterDictionary/'\n",
    "\n",
    "# Load positive and negative words from master dictionary\n",
    "positive_words = set()\n",
    "negative_words = set()\n",
    "with open(os.path.join(dictionary_dir, 'positive-words.txt'), 'r', encoding='latin1') as file:\n",
    "    positive_words.update(word.strip().lower() for word in file.readlines())\n",
    "with open(os.path.join(dictionary_dir, 'negative-words.txt'), 'r', encoding='latin1') as file:\n",
    "    negative_words.update(word.strip().lower() for word in file.readlines())\n",
    "\n",
    "# Create a list of dictionaries to store the positive and negative word counts for each URL id\n",
    "word_counts = []\n",
    "for filename in os.listdir(cleaned_dir):\n",
    "    if filename.endswith('_cleaned.txt'):\n",
    "        url_id = filename.split('_')[0]\n",
    "        with open(os.path.join(cleaned_dir, filename), 'r', encoding='latin1') as file:\n",
    "            text = file.read()\n",
    "        # Split the cleaned text into words\n",
    "        words = text.split()\n",
    "        # Count the number of positive and negative words\n",
    "        positive_count = sum(1 for word in words if word.lower() in positive_words)\n",
    "        negative_count = sum(1 for word in words if word.lower() in negative_words)\n",
    "        # Add the word counts to the list of dictionaries\n",
    "        word_counts.append({'URL_ID': url_id, 'Positive_Words': positive_count, 'Negative_Words': negative_count})\n",
    "\n",
    "# Create a pandas dataframe from the list of dictionaries\n",
    "df_word_counts = pd.DataFrame(word_counts)\n",
    "\n",
    "# Print the dataframe\n",
    "df_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfbb9e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>Positive Score</th>\n",
       "      <th>Negative Score</th>\n",
       "      <th>Polarity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>22</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.301587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.0</td>\n",
       "      <td>24</td>\n",
       "      <td>43</td>\n",
       "      <td>-0.283582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103.0</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.0</td>\n",
       "      <td>26</td>\n",
       "      <td>54</td>\n",
       "      <td>-0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>95.0</td>\n",
       "      <td>29</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.064516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>96.0</td>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.438596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>97.0</td>\n",
       "      <td>13</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.518519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>98.0</td>\n",
       "      <td>33</td>\n",
       "      <td>48</td>\n",
       "      <td>-0.185185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>99.0</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    URL_ID  Positive Score  Negative Score  Polarity Score\n",
       "0    100.0              22              41       -0.301587\n",
       "1    101.0               3               3        0.000000\n",
       "2    102.0              24              43       -0.283582\n",
       "3    103.0               6              24       -0.600000\n",
       "4    104.0              26              54       -0.350000\n",
       "..     ...             ...             ...             ...\n",
       "106   95.0              29              33       -0.064516\n",
       "107   96.0              16              41       -0.438596\n",
       "108   97.0              13              41       -0.518519\n",
       "109   98.0              33              48       -0.185185\n",
       "110   99.0              21              27       -0.125000\n",
       "\n",
       "[111 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_counts = df_word_counts.rename(columns={'Positive_Words': 'Positive Score', 'Negative_Words': 'Negative Score'})\n",
    "df_word_counts['Polarity Score'] = (df_word_counts['Positive Score'] - df_word_counts['Negative Score']) / ((df_word_counts['Positive Score'] + df_word_counts['Negative Score']) + 0.000001)\n",
    "df_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b678df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>Positive Score</th>\n",
       "      <th>Negative Score</th>\n",
       "      <th>Polarity Score</th>\n",
       "      <th>Subjectivity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>22</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.301587</td>\n",
       "      <td>0.081606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.0</td>\n",
       "      <td>24</td>\n",
       "      <td>43</td>\n",
       "      <td>-0.283582</td>\n",
       "      <td>0.112228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103.0</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.073350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.0</td>\n",
       "      <td>26</td>\n",
       "      <td>54</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>0.127389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>95.0</td>\n",
       "      <td>29</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.064516</td>\n",
       "      <td>0.105983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>96.0</td>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.438596</td>\n",
       "      <td>0.056604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>97.0</td>\n",
       "      <td>13</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.518519</td>\n",
       "      <td>0.099083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>98.0</td>\n",
       "      <td>33</td>\n",
       "      <td>48</td>\n",
       "      <td>-0.185185</td>\n",
       "      <td>0.130225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>99.0</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.091954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    URL_ID  Positive Score  Negative Score  Polarity Score  Subjectivity Score\n",
       "0    100.0              22              41       -0.301587            0.081606\n",
       "1    101.0               3               3        0.000000            0.069767\n",
       "2    102.0              24              43       -0.283582            0.112228\n",
       "3    103.0               6              24       -0.600000            0.073350\n",
       "4    104.0              26              54       -0.350000            0.127389\n",
       "..     ...             ...             ...             ...                 ...\n",
       "106   95.0              29              33       -0.064516            0.105983\n",
       "107   96.0              16              41       -0.438596            0.056604\n",
       "108   97.0              13              41       -0.518519            0.099083\n",
       "109   98.0              33              48       -0.185185            0.130225\n",
       "110   99.0              21              27       -0.125000            0.091954\n",
       "\n",
       "[111 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read cleaned article texts and calculate total words after cleaning\n",
    "df_word_counts['Cleaned Text'] = [open(f'Cleaned_Article_Texts/{url_id}_cleaned.txt', 'r', encoding='utf-8').read() for url_id in df_word_counts['URL_ID']]\n",
    "df_word_counts['Total Words'] = df_word_counts['Cleaned Text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Calculate subjectivity score\n",
    "df_word_counts['Subjectivity Score'] = (df_word_counts['Positive Score'] + df_word_counts['Negative Score']) / (df_word_counts['Total Words'] + 0.000001).drop(columns=['Cleaned Text', 'Total Words'], axis=1)\n",
    "df_word_counts = df_word_counts.drop(columns=['Cleaned Text', 'Total Words'], axis=1)\n",
    "df1 = df_word_counts.copy()\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fd6703",
   "metadata": {},
   "source": [
    "### Readability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d657951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>Avg_Sentence_Length</th>\n",
       "      <th>Percent_Complex_Words</th>\n",
       "      <th>Fog_Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>23.571429</td>\n",
       "      <td>9.469697</td>\n",
       "      <td>13.216450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.0</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>5.825243</td>\n",
       "      <td>10.570097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.0</td>\n",
       "      <td>20.066667</td>\n",
       "      <td>8.554817</td>\n",
       "      <td>11.448594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103.0</td>\n",
       "      <td>20.514286</td>\n",
       "      <td>6.267409</td>\n",
       "      <td>10.712678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.0</td>\n",
       "      <td>24.612245</td>\n",
       "      <td>10.530680</td>\n",
       "      <td>14.057170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  URL_ID  Avg_Sentence_Length  Percent_Complex_Words  Fog_Index\n",
       "0  100.0            23.571429               9.469697  13.216450\n",
       "1  101.0            20.600000               5.825243  10.570097\n",
       "2  102.0            20.066667               8.554817  11.448594\n",
       "3  103.0            20.514286               6.267409  10.712678\n",
       "4  104.0            24.612245              10.530680  14.057170"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "articles_dir = \"Extracted article texts\"\n",
    "df2 = pd.DataFrame(columns=[\"URL_ID\", \"Avg_Sentence_Length\", \"Percent_Complex_Words\", \"Fog_Index\"])\n",
    "\n",
    "for filename in os.listdir(articles_dir):\n",
    "    url_id = os.path.splitext(filename)[0]\n",
    "    with open(os.path.join(articles_dir, filename), 'r', encoding='latin1') as file:\n",
    "        text = file.read()\n",
    "        sentences = sent_tokenize(text)\n",
    "        words = word_tokenize(text)\n",
    "        \n",
    "        # Average Sentence Length\n",
    "        avg_sentence_length = len(words) / len(sentences)\n",
    "        \n",
    "        # Percentage of Complex Words\n",
    "        complex_words = set()\n",
    "        doc = nlp(text)\n",
    "        for token in doc:\n",
    "            if token.is_alpha and not token.is_stop and len(token.text) > 2 and token.pos_ in {'ADJ', 'ADV'}:\n",
    "                complex_words.add(token.text.lower())\n",
    "        num_complex_words = sum([1 for word in words if word.lower() in complex_words])\n",
    "        percent_complex_words = (num_complex_words / len(words)) * 100\n",
    "        \n",
    "        # Fog Index\n",
    "        fog_index = 0.4 * (avg_sentence_length + percent_complex_words)\n",
    "        \n",
    "        # Add to DataFrame\n",
    "        df2 = df2.append({\"URL_ID\": url_id, \"Avg_Sentence_Length\": avg_sentence_length,\n",
    "                        \"Percent_Complex_Words\": percent_complex_words, \"Fog_Index\": fog_index}, ignore_index=True)\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd53bce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Avg Sentence Length</th>\n",
       "      <th>Percentage of Complex Words</th>\n",
       "      <th>Fog Index</th>\n",
       "      <th>Average Number of Words per Sentence</th>\n",
       "      <th>Complex Word Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>23.571429</td>\n",
       "      <td>6.287879</td>\n",
       "      <td>11.943723</td>\n",
       "      <td>23.571429</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.0</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>3.398058</td>\n",
       "      <td>9.599223</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.0</td>\n",
       "      <td>20.066667</td>\n",
       "      <td>5.066445</td>\n",
       "      <td>10.053245</td>\n",
       "      <td>20.066667</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103.0</td>\n",
       "      <td>20.514286</td>\n",
       "      <td>3.899721</td>\n",
       "      <td>9.765603</td>\n",
       "      <td>20.514286</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.0</td>\n",
       "      <td>24.612245</td>\n",
       "      <td>7.296849</td>\n",
       "      <td>12.763638</td>\n",
       "      <td>24.612245</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>105.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>14.050000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>106.0</td>\n",
       "      <td>34.800000</td>\n",
       "      <td>3.448276</td>\n",
       "      <td>15.299310</td>\n",
       "      <td>34.800000</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>107.0</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>5.481728</td>\n",
       "      <td>10.792691</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>108.0</td>\n",
       "      <td>33.866667</td>\n",
       "      <td>6.397638</td>\n",
       "      <td>16.105722</td>\n",
       "      <td>33.866667</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>109.0</td>\n",
       "      <td>26.166667</td>\n",
       "      <td>1.528662</td>\n",
       "      <td>11.078132</td>\n",
       "      <td>26.166667</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>110.0</td>\n",
       "      <td>24.361702</td>\n",
       "      <td>3.668122</td>\n",
       "      <td>11.211930</td>\n",
       "      <td>24.361702</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>111.0</td>\n",
       "      <td>21.961538</td>\n",
       "      <td>3.327496</td>\n",
       "      <td>10.115614</td>\n",
       "      <td>21.961538</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>112.0</td>\n",
       "      <td>21.826923</td>\n",
       "      <td>3.964758</td>\n",
       "      <td>10.316672</td>\n",
       "      <td>21.826923</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>113.0</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>4.959631</td>\n",
       "      <td>12.183852</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>114.0</td>\n",
       "      <td>24.405797</td>\n",
       "      <td>4.513064</td>\n",
       "      <td>11.567544</td>\n",
       "      <td>24.405797</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>115.0</td>\n",
       "      <td>28.241379</td>\n",
       "      <td>4.090354</td>\n",
       "      <td>12.932693</td>\n",
       "      <td>28.241379</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>116.0</td>\n",
       "      <td>82.454545</td>\n",
       "      <td>3.087100</td>\n",
       "      <td>34.216658</td>\n",
       "      <td>82.454545</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>117.0</td>\n",
       "      <td>29.166667</td>\n",
       "      <td>6.181818</td>\n",
       "      <td>14.139394</td>\n",
       "      <td>29.166667</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>118.0</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>3.604903</td>\n",
       "      <td>8.741961</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>119.0</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>6.451613</td>\n",
       "      <td>12.500645</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      URL  Avg Sentence Length  Percentage of Complex Words  Fog Index  \\\n",
       "0   100.0            23.571429                     6.287879  11.943723   \n",
       "1   101.0            20.600000                     3.398058   9.599223   \n",
       "2   102.0            20.066667                     5.066445  10.053245   \n",
       "3   103.0            20.514286                     3.899721   9.765603   \n",
       "4   104.0            24.612245                     7.296849  12.763638   \n",
       "5   105.0            32.000000                     3.125000  14.050000   \n",
       "6   106.0            34.800000                     3.448276  15.299310   \n",
       "7   107.0            21.500000                     5.481728  10.792691   \n",
       "8   108.0            33.866667                     6.397638  16.105722   \n",
       "9   109.0            26.166667                     1.528662  11.078132   \n",
       "10  110.0            24.361702                     3.668122  11.211930   \n",
       "11  111.0            21.961538                     3.327496  10.115614   \n",
       "12  112.0            21.826923                     3.964758  10.316672   \n",
       "13  113.0            25.500000                     4.959631  12.183852   \n",
       "14  114.0            24.405797                     4.513064  11.567544   \n",
       "15  115.0            28.241379                     4.090354  12.932693   \n",
       "16  116.0            82.454545                     3.087100  34.216658   \n",
       "17  117.0            29.166667                     6.181818  14.139394   \n",
       "18  118.0            18.250000                     3.604903   8.741961   \n",
       "19  119.0            24.800000                     6.451613  12.500645   \n",
       "\n",
       "    Average Number of Words per Sentence  Complex Word Count  \n",
       "0                              23.571429                 275  \n",
       "1                              20.600000                  27  \n",
       "2                              20.066667                 218  \n",
       "3                              20.514286                 141  \n",
       "4                              24.612245                 284  \n",
       "5                              32.000000                 184  \n",
       "6                              34.800000                  31  \n",
       "7                              21.500000                  95  \n",
       "8                              33.866667                 211  \n",
       "9                              26.166667                  79  \n",
       "10                             24.361702                 227  \n",
       "11                             21.961538                 236  \n",
       "12                             21.826923                 236  \n",
       "13                             25.500000                 178  \n",
       "14                             24.405797                 302  \n",
       "15                             28.241379                 347  \n",
       "16                             82.454545                  91  \n",
       "17                             29.166667                 385  \n",
       "18                             18.250000                 167  \n",
       "19                             24.800000                  88  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import spacy\n",
    "import syllables\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "articles_dir = \"Extracted article texts\"\n",
    "\n",
    "data = {'URL': [], 'Avg Sentence Length': [], 'Percentage of Complex Words': [], 'Fog Index': [], 'Average Number of Words per Sentence': [], 'Complex Word Count': []}\n",
    "\n",
    "for filename in os.listdir(articles_dir):\n",
    "    url_id = filename[:-4]\n",
    "    with open(os.path.join(articles_dir, filename), 'r', encoding='latin1') as file:\n",
    "        text = file.read()\n",
    "        sentences = sent_tokenize(text)\n",
    "        words = word_tokenize(text)\n",
    "\n",
    "        # Average Sentence Length\n",
    "        avg_sentence_length = len(words) / len(sentences)\n",
    "\n",
    "        # Percentage of Complex Words\n",
    "        complex_words = set()\n",
    "        for filename in os.listdir(articles_dir):\n",
    "            with open(os.path.join(articles_dir, filename), 'r', encoding='latin1') as file:\n",
    "                text = file.read()\n",
    "                doc = nlp(text)\n",
    "                for token in doc:\n",
    "                    if token.is_alpha and not token.is_stop and len(token.text) > 2 and token.pos_ in {'ADJ', 'ADV'}:\n",
    "                        complex_words.add(token.text.lower())\n",
    "        num_complex_words = sum([1 for word in words if syllables.estimate(word) > 2 and word.lower() in complex_words])\n",
    "        percent_complex_words = (num_complex_words / len(words)) * 100\n",
    "\n",
    "        # Fog Index\n",
    "        fog_index = 0.4 * (avg_sentence_length + percent_complex_words)\n",
    "\n",
    "        # Average Number of Words per Sentence\n",
    "        avg_words_per_sentence = len(words) / len(sentences)\n",
    "\n",
    "        # Complex Word Count\n",
    "        complex_word_count = sum([1 for word in words if syllables.estimate(word) > 2])\n",
    "\n",
    "        data['URL'].append(url_id)\n",
    "        data['Avg Sentence Length'].append(avg_sentence_length)\n",
    "        data['Percentage of Complex Words'].append(percent_complex_words)\n",
    "        data['Fog Index'].append(fog_index)\n",
    "        data['Average Number of Words per Sentence'].append(avg_words_per_sentence)\n",
    "        data['Complex Word Count'].append(complex_word_count)\n",
    "\n",
    "df4 = pd.DataFrame(data)\n",
    "\n",
    "df4.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c89a8707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def count_syllables(word):\n",
    "    vowels = \"aeiou\"\n",
    "    count = 0\n",
    "    prev_char_was_vowel = False\n",
    "    for char in word:\n",
    "        char = char.lower()\n",
    "        if char in vowels:\n",
    "            if not prev_char_was_vowel:\n",
    "                count += 1\n",
    "                prev_char_was_vowel = True\n",
    "        else:\n",
    "            prev_char_was_vowel = False\n",
    "            if char == 'e':\n",
    "                if count == 0:\n",
    "                    count += 1\n",
    "                if count > 1:\n",
    "                    count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "def count_personal_pronouns(text):\n",
    "    count = 0\n",
    "    personal_pronouns = ['i', 'we', 'my', 'ours', 'us']\n",
    "    for pronoun in personal_pronouns:\n",
    "        count += len(re.findall(rf\"\\b{pronoun}\\b\", text, flags=re.IGNORECASE))\n",
    "    return count\n",
    "\n",
    "cleaned_articles_dir = \"Cleaned_Article_Texts\"\n",
    "df3 = pd.DataFrame(columns=['url_id', 'word_count', 'syllables_per_word', 'personal_pronouns', 'avg_word_length'])\n",
    "\n",
    "for filename in os.listdir(cleaned_articles_dir):\n",
    "    url_id = filename.split(\"_\")[0]\n",
    "    with open(os.path.join(cleaned_articles_dir, filename), 'r', encoding='latin1') as file:\n",
    "        text = file.read()\n",
    "        words = re.findall(r'\\w+', text)\n",
    "        cleaned_words = [word for word in words if word.isalpha()]\n",
    "        word_count = len(cleaned_words)\n",
    "        \n",
    "        # Syllable Count Per Word\n",
    "        syllables_per_word = [count_syllables(word) for word in cleaned_words]\n",
    "        \n",
    "        # Personal Pronouns\n",
    "        personal_pronouns = count_personal_pronouns(text)\n",
    "        \n",
    "        # Average Word Length\n",
    "        total_word_length = sum([len(word) for word in cleaned_words])\n",
    "        avg_word_length = total_word_length / len(cleaned_words)\n",
    "        \n",
    "        # Add results to dataframe\n",
    "        df3 = df3.append({'url_id': url_id, \n",
    "                                        'word_count': word_count,\n",
    "                                        'syllables_per_word': syllables_per_word,\n",
    "                                        'personal_pronouns': personal_pronouns,\n",
    "                                        'avg_word_length': avg_word_length}, \n",
    "                                        ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "967e16ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_id</th>\n",
       "      <th>word_count</th>\n",
       "      <th>syllables_per_word</th>\n",
       "      <th>personal_pronouns</th>\n",
       "      <th>avg_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>606</td>\n",
       "      <td>[4, 2, 2, 1, 1, 1, 5, 5, 5, 4, 3, 1, 1, 1, 2, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>6.859736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.0</td>\n",
       "      <td>66</td>\n",
       "      <td>[2, 2, 2, 2, 3, 5, 2, 3, 1, 1, 1, 3, 3, 1, 2, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.303030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.0</td>\n",
       "      <td>482</td>\n",
       "      <td>[2, 3, 2, 2, 1, 2, 3, 2, 1, 1, 2, 1, 5, 3, 1, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.761411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103.0</td>\n",
       "      <td>293</td>\n",
       "      <td>[4, 4, 1, 2, 3, 3, 2, 3, 5, 4, 2, 1, 3, 1, 3, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.771331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.0</td>\n",
       "      <td>550</td>\n",
       "      <td>[1, 2, 4, 4, 4, 3, 2, 3, 1, 2, 3, 3, 3, 2, 2, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>7.180000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  url_id word_count                                 syllables_per_word  \\\n",
       "0  100.0        606  [4, 2, 2, 1, 1, 1, 5, 5, 5, 4, 3, 1, 1, 1, 2, ...   \n",
       "1  101.0         66  [2, 2, 2, 2, 3, 5, 2, 3, 1, 1, 1, 3, 3, 1, 2, ...   \n",
       "2  102.0        482  [2, 3, 2, 2, 1, 2, 3, 2, 1, 1, 2, 1, 5, 3, 1, ...   \n",
       "3  103.0        293  [4, 4, 1, 2, 3, 3, 2, 3, 5, 4, 2, 1, 3, 1, 3, ...   \n",
       "4  104.0        550  [1, 2, 4, 4, 4, 3, 2, 3, 1, 2, 3, 3, 3, 2, 2, ...   \n",
       "\n",
       "  personal_pronouns  avg_word_length  \n",
       "0                 1         6.859736  \n",
       "1                 0         6.303030  \n",
       "2                 0         6.761411  \n",
       "3                 0         6.771331  \n",
       "4                 2         7.180000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9be8838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>Positive Score</th>\n",
       "      <th>Negative Score</th>\n",
       "      <th>Polarity Score</th>\n",
       "      <th>Subjectivity Score</th>\n",
       "      <th>Avg Sentence Length</th>\n",
       "      <th>Percentage of Complex Words</th>\n",
       "      <th>Fog Index</th>\n",
       "      <th>Average Number of Words Per Sentence</th>\n",
       "      <th>Complex Word Count</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Syllables Per Word</th>\n",
       "      <th>Personal Pronouns</th>\n",
       "      <th>Average Word Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>22</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.301587</td>\n",
       "      <td>0.081606</td>\n",
       "      <td>23.571429</td>\n",
       "      <td>6.287879</td>\n",
       "      <td>11.943723</td>\n",
       "      <td>23.571429</td>\n",
       "      <td>275</td>\n",
       "      <td>606</td>\n",
       "      <td>[4, 2, 2, 1, 1, 1, 5, 5, 5, 4, 3, 1, 1, 1, 2, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>6.859736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>3.398058</td>\n",
       "      <td>9.599223</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>27</td>\n",
       "      <td>66</td>\n",
       "      <td>[2, 2, 2, 2, 3, 5, 2, 3, 1, 1, 1, 3, 3, 1, 2, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.303030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.0</td>\n",
       "      <td>24</td>\n",
       "      <td>43</td>\n",
       "      <td>-0.283582</td>\n",
       "      <td>0.112228</td>\n",
       "      <td>20.066667</td>\n",
       "      <td>5.066445</td>\n",
       "      <td>10.053245</td>\n",
       "      <td>20.066667</td>\n",
       "      <td>218</td>\n",
       "      <td>482</td>\n",
       "      <td>[2, 3, 2, 2, 1, 2, 3, 2, 1, 1, 2, 1, 5, 3, 1, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.761411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103.0</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.073350</td>\n",
       "      <td>20.514286</td>\n",
       "      <td>3.899721</td>\n",
       "      <td>9.765603</td>\n",
       "      <td>20.514286</td>\n",
       "      <td>141</td>\n",
       "      <td>293</td>\n",
       "      <td>[4, 4, 1, 2, 3, 3, 2, 3, 5, 4, 2, 1, 3, 1, 3, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.771331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.0</td>\n",
       "      <td>26</td>\n",
       "      <td>54</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>0.127389</td>\n",
       "      <td>24.612245</td>\n",
       "      <td>7.296849</td>\n",
       "      <td>12.763638</td>\n",
       "      <td>24.612245</td>\n",
       "      <td>284</td>\n",
       "      <td>550</td>\n",
       "      <td>[1, 2, 4, 4, 4, 3, 2, 3, 1, 2, 3, 3, 3, 2, 2, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>7.180000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  URL_ID  Positive Score  Negative Score  Polarity Score  Subjectivity Score  \\\n",
       "0  100.0              22              41       -0.301587            0.081606   \n",
       "1  101.0               3               3        0.000000            0.069767   \n",
       "2  102.0              24              43       -0.283582            0.112228   \n",
       "3  103.0               6              24       -0.600000            0.073350   \n",
       "4  104.0              26              54       -0.350000            0.127389   \n",
       "\n",
       "   Avg Sentence Length  Percentage of Complex Words  Fog Index  \\\n",
       "0            23.571429                     6.287879  11.943723   \n",
       "1            20.600000                     3.398058   9.599223   \n",
       "2            20.066667                     5.066445  10.053245   \n",
       "3            20.514286                     3.899721   9.765603   \n",
       "4            24.612245                     7.296849  12.763638   \n",
       "\n",
       "   Average Number of Words Per Sentence  Complex Word Count Word Count  \\\n",
       "0                             23.571429                 275        606   \n",
       "1                             20.600000                  27         66   \n",
       "2                             20.066667                 218        482   \n",
       "3                             20.514286                 141        293   \n",
       "4                             24.612245                 284        550   \n",
       "\n",
       "                                  Syllables Per Word Personal Pronouns  \\\n",
       "0  [4, 2, 2, 1, 1, 1, 5, 5, 5, 4, 3, 1, 1, 1, 2, ...                 1   \n",
       "1  [2, 2, 2, 2, 3, 5, 2, 3, 1, 1, 1, 3, 3, 1, 2, ...                 0   \n",
       "2  [2, 3, 2, 2, 1, 2, 3, 2, 1, 1, 2, 1, 5, 3, 1, ...                 0   \n",
       "3  [4, 4, 1, 2, 3, 3, 2, 3, 5, 4, 2, 1, 3, 1, 3, ...                 0   \n",
       "4  [1, 2, 4, 4, 4, 3, 2, 3, 1, 2, 3, 3, 3, 2, 2, ...                 2   \n",
       "\n",
       "   Average Word Length  \n",
       "0             6.859736  \n",
       "1             6.303030  \n",
       "2             6.761411  \n",
       "3             6.771331  \n",
       "4             7.180000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Avg Sentence Length'] = df4['Avg Sentence Length']\n",
    "df1['Percentage of Complex Words'] = df4['Percentage of Complex Words']\n",
    "df1['Fog Index'] = df4['Fog Index']\n",
    "df1['Average Number of Words Per Sentence'] = df4['Average Number of Words per Sentence']\n",
    "df1['Complex Word Count'] = df4['Complex Word Count']\n",
    "df1['Word Count'] = df3['word_count']\n",
    "df1['Syllables Per Word'] = df3['syllables_per_word']\n",
    "df1['Personal Pronouns'] = df3['personal_pronouns']\n",
    "df1['Average Word Length'] = df3['avg_word_length']\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffb6ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_excel('Final.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9272420f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
